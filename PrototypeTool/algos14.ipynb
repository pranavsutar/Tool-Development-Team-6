{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Smell:- context-independent, data value-based indications of latent data quality issues caused by poor practices that may lead to problems in the future.\n",
      "We need  to detect data smells in the dataset and suggest the user to fix them.\n",
      "\n",
      "14 data smells identified in the \"Data Smells in Public Datasets\" paper, categorized by type:\n",
      "Redundant value smells:\n",
      "    red-corr: Correlated features\n",
      "    red-uid: Unique identifiers\n",
      "    red-dup: Duplicate examples\n",
      "Categorical value smells:\n",
      "    cat-hierarchy: Hierarchy from label encoding\n",
      "    cat-bin: Binning categorical features→categorical values with large cardinality + one-hot-encoding\n",
      "Missing value smells:\n",
      "    miss-null: Missing values\n",
      "    miss-sp-val: Special missing values\n",
      "    miss-bin: Binary missing values\n",
      "String value smells:\n",
      "    str-num: Numerical feature as string\n",
      "    str-sanitise: Strings with special characters\n",
      "    str-human: Strings in human-friendly formats\n",
      "Miscellaneous value smells:\n",
      "    misc-unit: Unknown unit of measure\n",
      "    misc-balance: Imbalanced examples\n",
      "    misc-sensitive: Presence of sensitive features\n",
      "\n",
      "Todo: To detect data smells, and suggest the user to fix them\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ToDo = '''\n",
    "Data Smell:- context-independent, data value-based indications of latent data quality issues caused by poor practices that may lead to problems in the future.\n",
    "We need  to detect data smells in the dataset and suggest the user to fix them.\n",
    "\n",
    "14 data smells identified in the \"Data Smells in Public Datasets\" paper, categorized by type:\n",
    "Redundant value smells:\n",
    "    red-corr: Correlated features\n",
    "    red-uid: Unique identifiers\n",
    "    red-dup: Duplicate examples\n",
    "Categorical value smells:\n",
    "    cat-hierarchy: Hierarchy from label encoding\n",
    "    cat-bin: Binning categorical features→categorical values with large cardinality + one-hot-encoding\n",
    "Missing value smells:\n",
    "    miss-null: Missing values\n",
    "    miss-sp-val: Special missing values\n",
    "    miss-bin: Binary missing values\n",
    "String value smells:\n",
    "    str-num: Numerical feature as string\n",
    "    str-sanitise: Strings with special characters\n",
    "    str-human: Strings in human-friendly formats\n",
    "Miscellaneous value smells:\n",
    "    misc-unit: Unknown unit of measure\n",
    "    misc-balance: Imbalanced examples\n",
    "    misc-sensitive: Presence of sensitive features\n",
    "\n",
    "Todo: To detect data smells, and suggest the user to fix them\n",
    "'''\n",
    "print(ToDo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>30.83</th>\n",
       "      <th>0</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>w</th>\n",
       "      <th>v</th>\n",
       "      <th>1.25</th>\n",
       "      <th>t</th>\n",
       "      <th>t.1</th>\n",
       "      <th>01</th>\n",
       "      <th>f</th>\n",
       "      <th>g.1</th>\n",
       "      <th>00202</th>\n",
       "      <th>0.1</th>\n",
       "      <th>+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>32.08</td>\n",
       "      <td>4.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>2.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00360</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   b  30.83      0  u  g  w  v  1.25  t t.1  01  f g.1  00202  0.1  +\n",
       "0  a  58.67  4.460  u  g  q  h  3.04  t   t   6  f   g  00043  560  +\n",
       "1  a  24.50  0.500  u  g  q  h  1.50  t   f   0  f   g  00280  824  +\n",
       "2  b  27.83  1.540  u  g  w  v  3.75  t   t   5  t   g  00100    3  +\n",
       "3  b  20.17  5.625  u  g  w  v  1.71  t   f   0  f   s  00120    0  +\n",
       "4  b  32.08  4.000  u  g  m  v  2.50  t   f   0  t   g  00360    0  +"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['b', '30.83', '0', 'u', 'g', 'w', 'v', '1.25', 't', 't.1', '01', 'f',\n",
       "       'g.1', '00202', '0.1', '+'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b         object\n",
       "30.83     object\n",
       "0        float64\n",
       "u         object\n",
       "g         object\n",
       "w         object\n",
       "v         object\n",
       "1.25     float64\n",
       "t         object\n",
       "t.1       object\n",
       "01         int64\n",
       "f         object\n",
       "g.1       object\n",
       "00202     object\n",
       "0.1        int64\n",
       "+         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking presence of Headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file does not have headings in the first row.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "filename = \"data.csv\"\n",
    "\n",
    "# Open the CSV file in read mode\n",
    "with open(filename, 'r') as csvfile:\n",
    "\n",
    "  # Create a CSV reader object\n",
    "  csvreader = csv.reader(csvfile)\n",
    "\n",
    "  # Get the first row from the CSV file\n",
    "  first_row = next(csvreader)\n",
    "\n",
    "  # Check if the first row contains headings or not\n",
    "  if any(field.strip() != '' for field in first_row) and not any(field.strip().isdigit() for field in first_row):\n",
    "    print(\"The CSV file has headings in the first row.\")\n",
    "  else:\n",
    "    print(\"The CSV file does not have headings in the first row.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4 Missing Value Smells: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 4.4.1Missing Null(miss-null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for missing values\n",
    "missing_values_count = df.isnull().sum().sum()\n",
    "if missing_values_count == 0:\n",
    "    print(\"There are no missing values in the dataset.\")\n",
    "else:\n",
    "    print(\"There are missing values in the dataset.\")\n",
    "    print(\"Number of missing values:\", missing_values_count)\n",
    "    print(\"Percentage of missing values:\", round(missing_values_count / (df.shape[0] * df.shape[1]) * 100, 2), \"%\")\n",
    "\n",
    "    print(\"Missing values in each column:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) 4.4.2 miss-sp-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are special missing values in the dataset.\n",
      "Number of special missing values: 449\n",
      "Percentage of special missing values: 4.07 %\n",
      "Special missing values in each column:\n",
      "b : 12\n",
      "30.83 : 12\n",
      "0 : 0\n",
      "u : 6\n",
      "g : 6\n",
      "w : 9\n",
      "v : 9\n",
      "1.25 : 0\n",
      "t : 0\n",
      "t.1 : 0\n",
      "01 : 0\n",
      "f : 0\n",
      "g.1 : 0\n",
      "00202 : 13\n",
      "0.1 : 0\n",
      "+ : 382\n"
     ]
    }
   ],
   "source": [
    "# Check for special missing values\n",
    "special_missing_values = ['-', 'n/a', 'N/A', 'NA', '--', '?']\n",
    "pres = {val: 0 for val in special_missing_values}\n",
    "for val in special_missing_values:\n",
    "    pres[val] = df.isin([val]).sum().sum()\n",
    "\n",
    "if any(pres.values()):\n",
    "    print(\"There are special missing values in the dataset.\")\n",
    "    print(\"Number of special missing values:\", sum(pres.values()))\n",
    "    print(\"Percentage of special missing values:\", round(sum(pres.values()) / (df.shape[0] * df.shape[1]) * 100, 2), \"%\")\n",
    "    print(\"Special missing values in each column:\")\n",
    "    for col in df.columns:\n",
    "        print(col, \":\", df[col].isin(special_missing_values).sum())\n",
    "else:\n",
    "    print(\"There are no special missing values in the dataset.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 4.4.3 Binary missing values (miss-bin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no binary missing values with an implicit meaning in the dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bin_miss = False\n",
    "# Iterate over each column\n",
    "for col in df.columns:\n",
    "    # Check if there are any missing values in the column\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        # Check if the missing values are binary\n",
    "        if df[col].nunique() == 2:\n",
    "            # Check if there is an implicit meaning to the missing values\n",
    "            non_missing_values = df[col].dropna().unique()\n",
    "            if len(non_missing_values) == 1:\n",
    "                print(f\"{col} contains binary missing values with an implicit meaning of {non_missing_values[0]}\")\n",
    "                bin_miss = True\n",
    "\n",
    "if not bin_miss:\n",
    "    print(\"There are no binary missing values with an implicit meaning in the dataset.\")\n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Redundant Value Smells "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) 4.1.1 Correlated features (red-corr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum correlation value among any two values: 0.3222471778654087\n",
      "There are no highly correlated features in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Identify highly correlated features\n",
    "high_corr_features = set()\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7: # Change the threshold value as needed\n",
    "            colname = corr_matrix.columns[i]\n",
    "            high_corr_features.add(colname)\n",
    "# Highest cvalue of correlation on non-diagonal elements\n",
    "max_corr = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool)).stack().max()\n",
    "print(\"Maximum correlation value among any two values:\", max_corr)\n",
    "\n",
    "# print giving info\n",
    "if len(high_corr_features) > 0:\n",
    "    print(\"There are highly correlated features in the dataset.\")\n",
    "    print(\"Number of highly correlated features:\", len(high_corr_features))\n",
    "    print(\"Highly correlated features:\", high_corr_features)\n",
    "else:\n",
    "    print(\"There are no highly correlated features in the dataset.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) 4.1.2 Unique identifiers (red-uid) -     \n",
    "A machine learning model may learn some hidden relationship between the uids and the target values that produces a high accu-racy during training.  \n",
    "Although uids are useful when per-forming merge or join operations on two or more database tables, they become redundant when training machine learning models.   \n",
    " Their presence in a dataset is a   smell for potential problems in downstream stages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no unique identifier columns in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# Identify unique identifier columns\n",
    "uid_cols = []\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == len(df):\n",
    "        uid_cols.append(col)\n",
    "\n",
    "# Print info\n",
    "if len(uid_cols) > 0:\n",
    "    print(\"There are unique identifier columns in the dataset.\")\n",
    "    print(\"Number of unique identifier columns:\", len(uid_cols))\n",
    "    print(\"Unique identifier columns:\", uid_cols)\n",
    "else:\n",
    "    print(\"There are no unique identifier columns in the dataset.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) 1.3 Duplicate examples (red-dup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate examples in the dataset.\n"
     ]
    }
   ],
   "source": [
    "duplicates = df.duplicated()\n",
    "if any(duplicates):\n",
    "    print(\"Duplicate examples are present in the dataset.\")\n",
    "    print(\"Number of duplicate examples:\", duplicates.sum())\n",
    "    print(\"Indices of duplicate examples:\", df.index[duplicates].tolist())\n",
    "else:\n",
    "    print(\"There are no duplicate examples in the dataset.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Categorical Value Smells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (7)  4.2.1 Hierarchy from label encoding (cat-hierarchy)  \n",
    "Label encoding sensitive categorical features can introduce unwanted hierarchy amongst the values and lead to incorrect and biased results in machine learning models.  \n",
    "The presence of sensitive categorical features is a smell to avoid introducing bias into the model.  \n",
    "One-hot encoding technique can be used to avoid unwanted hierarchy amongst the values in sensitive categorical features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Check for label encoding hierarchy\\ncat_features = df.select_dtypes(include=[\\'object\\']).columns.tolist()\\nsensitive_cat_features = [\\'sex\\', \\'race\\']  # Add more sensitive categorical features as necessary\\nhierarchy_detected = False\\n\\nfor feature in cat_features:\\n    if feature not in sensitive_cat_features:\\n        levels = df[feature].unique().tolist()\\n        levels_encoding = dict(zip(levels, range(len(levels))))\\n        expected_encoding = sorted(levels_encoding.values())\\n        \\n        if list(levels_encoding.values()) != expected_encoding:\\n            print(f\"Hierarchy detected in categorical feature: {feature}\")\\n            hierarchy_detected = True\\n\\n# Suggest correction\\nif hierarchy_detected:\\n    print(\"Sensitive categorical features detected. Use one-hot encoding to avoid introducing bias in the model.\")\\nelse:\\n    print(\"No hierarchy detected in categorical features.\")\\n    '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define list of sensitive categorical features\n",
    "sensitive_features = ['race', 'gender', 'religion','nationality','']\n",
    "\n",
    "# Check if any of the sensitive features are present\n",
    "for feature in sensitive_features:\n",
    "    if feature in df.columns and df[feature].dtype == 'object':\n",
    "        print(f\"Sensitive feature {feature} detected. Consider using one-hot encoding instead of label encoding.\")\n",
    "\n",
    "'''\n",
    "\n",
    "# Check for label encoding hierarchy\n",
    "cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "sensitive_cat_features = ['sex', 'race']  # Add more sensitive categorical features as necessary\n",
    "hierarchy_detected = False\n",
    "\n",
    "for feature in cat_features:\n",
    "    if feature not in sensitive_cat_features:\n",
    "        levels = df[feature].unique().tolist()\n",
    "        levels_encoding = dict(zip(levels, range(len(levels))))\n",
    "        expected_encoding = sorted(levels_encoding.values())\n",
    "        \n",
    "        if list(levels_encoding.values()) != expected_encoding:\n",
    "            print(f\"Hierarchy detected in categorical feature: {feature}\")\n",
    "            hierarchy_detected = True\n",
    "\n",
    "# Suggest correction\n",
    "if hierarchy_detected:\n",
    "    print(\"Sensitive categorical features detected. Use one-hot encoding to avoid introducing bias in the model.\")\n",
    "else:\n",
    "    print(\"No hierarchy detected in categorical features.\")\n",
    "    '''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8)  4.2.2 Binning categorical features (cat-bin)  \n",
    "One-hot encoding a feature with high cardinality can result in a very large feature space and incur higher memory, disk space and computation costs throughout the machine learning lifecycle.  \n",
    "Presence of categorical features with high cardinality in their data is a smell to perform potential data transformations to reduce the cardinality.  \n",
    "A common practice amongst data scientists to address such a problem is to bin several values together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The '30.83' column has high cardinality with 349 unique values.\n",
      "The 'w' column has high cardinality with 15 unique values.\n",
      "The '00202' column has high cardinality with 170 unique values.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# loop through each column\n",
    "for col in df.columns:\n",
    "    # check if the column is categorical\n",
    "    if df[col].dtype == 'object':\n",
    "        # check the number of unique values\n",
    "        unique_vals = len(df[col].unique())\n",
    "        # set a threshold for high cardinality\n",
    "        threshold = 10\n",
    "        if unique_vals > threshold:\n",
    "            print(f\"The '{col}' column has high cardinality with {unique_vals} unique values.\")\n",
    "            # perform binning\n",
    "            \n",
    "            # ...\n",
    "        # else:\n",
    "            # print(f\"The '{col}' column has low cardinality with {unique_vals} unique values.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9)  4.3.1 Presence of sensitive features (misc-sensitive)  \n",
    "Sensitive features are high-impact features that contribute to biased and unfair model predictions.  \n",
    "Presence of sensitive features are a smell that may lead to biased and unfair model predictions.  \n",
    "Potential mitigation strategies include not using sensitive features during model training and introducing appropriate regularization techniques to combat bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no sensitive features in the dataset.\n",
      "No mitigation strategies are required.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for feature in sensitive_features:\n",
    "    if feature in df.columns:\n",
    "        print(f\"{feature} is a sensitive feature and should be handled with care.\")\n",
    "\n",
    "# Check for sensitive features\n",
    "sensitive_features = [\"age\", \"gender\", \"sex\", \"race\", \"religion\",\"ethnic\"]  # Add more sensitive features as necessary, or remove the current ones as we get clarity\n",
    "\n",
    "if any(feature in sensitive_features for feature in df.columns):\n",
    "    print(\"Sensitive features are present in the dataset.\")\n",
    "    print(\"Sensitive features:\", sensitive_features)\n",
    "   \n",
    "\n",
    "# Mitigation strategies \n",
    "    print(\"Potential mitigation strategies:\")\n",
    "    print(\"- Exclude sensitive features from the training set.\")\n",
    "    print(\"- Introduce appropriate regularization techniques to combat bias.\")\n",
    "    print(\"- Consider using trustworthy AI approaches to address issues regarding safety, robustness, explainability, fairness and privacy in machine learning models.\\n\")\n",
    "    print('Suggested code snippet:') \n",
    "    print('''    sensitive_features = [\"age\", \"gender\", \"sex\", \"race\", \"religion\"]\n",
    "    data_filtered = data.drop(sensitive_features, axis=1)\n",
    "    print(\"Sensitive features removed from dataset.\")''')\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"There are no sensitive features in the dataset.\")\n",
    "    print(\"No mitigation strategies are required.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) 4.3.2  Class Imbalance  (misc-balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Class imbalance detected in column 'b' with Class imbalance ratio: 0.03 \n",
      "\n",
      "2) Class imbalance detected in column '30.83' with Class imbalance ratio: 0.08 \n",
      "\n",
      "3) Class imbalance detected in column '0' with Class imbalance ratio: 0.05 \n",
      "\n",
      "4) Class imbalance detected in column 'u' with Class imbalance ratio: 0.0 \n",
      "\n",
      "5) Class imbalance detected in column 'g' with Class imbalance ratio: 0.0 \n",
      "\n",
      "6) Class imbalance detected in column 'w' with Class imbalance ratio: 0.02 \n",
      "\n",
      "7) Class imbalance detected in column 'v' with Class imbalance ratio: 0.01 \n",
      "\n",
      "8) Class imbalance detected in column '1.25' with Class imbalance ratio: 0.01 \n",
      "\n",
      "9) Class imbalance detected in column '01' with Class imbalance ratio: 0.0 \n",
      "\n",
      "10) Class imbalance detected in column 'g.1' with Class imbalance ratio: 0.01 \n",
      "\n",
      "11) Class imbalance detected in column '00202' with Class imbalance ratio: 0.01 \n",
      "\n",
      "12) Class imbalance detected in column '0.1' with Class imbalance ratio: 0.0 \n",
      "\n",
      "13) Class imbalance detected in column '+' with Class imbalance ratio: 0.0 \n",
      "\n",
      "Potential mitigation strategies:\n",
      "- Use appropriate sampling techniques to balance the classes.\n",
      "- Use appropriate evaluation metrics.\n",
      "- Use appropriate regularization techniques to combat bias.\n"
     ]
    }
   ],
   "source": [
    "imb = False; nu = 1\n",
    "# Check for class imbalance\n",
    "for col in df.columns:\n",
    "    class_counts = df[col].value_counts()\n",
    "    if class_counts.min() / class_counts.max() < 0.1:\n",
    "        print(f\"{nu}) Class imbalance detected in column '{col}' with \", end= '')\n",
    "        imb = True        \n",
    "        print(\"Class imbalance ratio:\", round(class_counts.min() / class_counts.max(), 2),'\\n')\n",
    "        nu += 1\n",
    "        # ck = class_counts.to_dict()\n",
    "        # # print few elements of dictionary\n",
    "        # print(\"Class counts:\", {k: ck[k] for k in list(ck)[:5]}, '... etc')\n",
    "\n",
    "if imb:\n",
    "    print(\"Potential mitigation strategies:\")\n",
    "    print(\"- Use appropriate sampling techniques to balance the classes.\")\n",
    "    print(\"- Use appropriate evaluation metrics like F1 score, precision, recall, etc. as accuracy is not a good metric for imbalanced datasets.\")\n",
    "    print(\"- Use appropriate regularization techniques like class weights to combat bias.\")\n",
    "else:\n",
    "    print(\"There is no class imbalance in the dataset.\")\n",
    "    print(\"No mitigation strategies are required.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) 4.3.3 Outliers  (misc-out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Column 0 has 2.467343976777939% outliers\n",
      "2) Column 1.25 has 9.143686502177069% outliers\n",
      "3) Column 01 has 11.46589259796807% outliers\n",
      "4) Column 0.1 has 16.25544267053701% outliers\n",
      "\n",
      "The dataset has outliers\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot boxplots for all numerical columns\n",
    "sns.boxplot(data=df.select_dtypes(include=['float64', 'int64']))\n",
    "# Visualize boxplots to detect outliers\n",
    "nu = 1;hasOutliers = False\n",
    "for col in df.columns:\n",
    "    # if its numerical column, then print the percentage of outlier\n",
    "    if df[col].dtype == 'float64' or df[col].dtype == 'int64':\n",
    "        # Calculate the first and third quartile\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        # Calculate the interquartile range\n",
    "        IQR = Q3 - Q1\n",
    "        # Calculate the outlier step\n",
    "        outlier_step = 1.5 * IQR\n",
    "        # Calculate the number of outliers\n",
    "        num_outliers = len(df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step)])\n",
    "        # Calculate the percentage of outliers\n",
    "        perc_outliers = num_outliers / len(df) * 100\n",
    "        print(f'{nu}) Column {col} has {perc_outliers}% outliers')\n",
    "        nu += 1\n",
    "        if perc_outliers > 0:\n",
    "            hasOutliers = True\n",
    "\n",
    "if hasOutliers:\n",
    "    print('\\nThe dataset has outliers')\n",
    "else:\n",
    "    print('\\nThe dataset does not have outliers')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 String Value Smells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) 4.5.1  Strings with special characters (str-sanitise):  \n",
    "        Presence of leading and trailing whitespaces and special characters in structured data can create potential problems in the data analysis stage.  \n",
    "        Categorical features represented as strings can confuse data analysis tools and lead to false results.  \n",
    "        Handling presence of special characters in string features requires a case-by-case analysis and solution, but removing leading and trailing whitespaces is a common task.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def detect_special_characters(df):\n",
    "    special_char_features = []\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            pattern = re.compile('[^A-Za-z0-9\\s]+')\n",
    "            match = pattern.search(df[col].iloc[0])\n",
    "            if match:\n",
    "                special_char_features.append(col)\n",
    "    if len(special_char_features) > 0:\n",
    "        print(\"There are features with special characters in the dataset.\")\n",
    "        print(\"Features with special characters:\", special_char_features)\n",
    "    else:\n",
    "        print(\"There are no features with special characters in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no columns with trailing spaces in the dataset.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a list to store the column names with trailing spaces\n",
    "cols_with_trailing_spaces = []\n",
    "\n",
    "# loop through each column in the dataset\n",
    "for col in df.columns:\n",
    "    # check if the column is a string type\n",
    "    if df[col].dtype == 'object':\n",
    "        # check if the column contains trailing spaces\n",
    "        if df[col].str.endswith(' ').any():\n",
    "            cols_with_trailing_spaces.append(col)\n",
    "\n",
    "# print the columns with trailing spaces\n",
    "if len(cols_with_trailing_spaces) > 0:\n",
    "    print(\"There are columns with trailing spaces in the dataset.\")\n",
    "    print(\"Columns with trailing spaces:\", cols_with_trailing_spaces)\n",
    "else:\n",
    "    print(\"There are no columns with trailing spaces in the dataset.\")\n",
    "\n",
    "    \n",
    "# Check for different string interpretations due to capital letters usage\n",
    "for col in df.select_dtypes(include=['object']):\n",
    "    unique_vals = df[col].str.lower().unique()\n",
    "    if len(unique_vals) != len(set(unique_vals)):\n",
    "        print(f\"Column '{col}' contains different string interpretations due to capital letters usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # refactoring: \n",
    "# for col in df.select_dtypes(include=['object']):\n",
    "#     df[col] = df[col].str.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(13) 4.5.2 Numerical features as string (str-num):\n",
    "The presence of features whose name indicates numerical type data, but the data analysis tool interprets the type as string is a smell.\n",
    "Extracting valuable numerical information from such features can be beneficial for model training.\n",
    "Machine learning models tend to perform better when trained with more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: []\n",
      "Numerical columns: []\n",
      "Numerical columns: ['0']\n",
      "Numerical columns: ['0']\n",
      "Numerical columns: ['0']\n",
      "Numerical columns: ['0']\n",
      "Numerical columns: ['0']\n",
      "Numerical columns: ['0', '1.25']\n",
      "Numerical columns: ['0', '1.25']\n",
      "Numerical columns: ['0', '1.25']\n",
      "Numerical columns: ['0', '1.25', '01']\n",
      "Numerical columns: ['0', '1.25', '01']\n",
      "Numerical columns: ['0', '1.25', '01']\n",
      "Numerical columns: ['0', '1.25', '01']\n",
      "Numerical columns: ['0', '1.25', '01', '0.1']\n",
      "Numerical columns: ['0', '1.25', '01', '0.1']\n",
      "For Correcting the error:\n",
      " Code snippet:\n",
      "for column in df.columns:\n",
      "\n",
      "    # check if the column contains only numerical values\n",
      "    if df[column].apply(lambda x: str(x).replace('.', '').isdigit()).all():\n",
      "        \n",
      "        # if the column contains only numerical values, convert the data type to float\n",
      "        df[column] = df[column].astype(float)\n",
      "    \n",
      "# save the corrected dataset to a new file\n",
      "df.to_csv(\"corrected_data.csv\", index=False)\n"
     ]
    }
   ],
   "source": [
    "# create empty list to store the column names of numerical features\n",
    "numerical_columns = []\n",
    "\n",
    "# loop through each column in the dataset\n",
    "for column in df.columns:\n",
    "\n",
    "\n",
    "    # check if the column contains only numerical values\n",
    "    if df[column].apply(lambda x: str(x).replace('.', '').isdigit()).all():\n",
    "        \n",
    "        # if the column contains only numerical values, add its name to the list of numerical columns\n",
    "        numerical_columns.append(column)\n",
    "    # print the list of numerical columns\n",
    "    print(\"Numerical columns:\", numerical_columns)\n",
    "\n",
    "# code for correcting numerical features as strings\n",
    "# loop through each column in the dataset\n",
    "print('For Correcting the error:\\n Code snippet:')\n",
    "\n",
    "print('''for column in df.columns:\n",
    "\n",
    "    # check if the column contains only numerical values\n",
    "    if df[column].apply(lambda x: str(x).replace('.', '').isdigit()).all():\n",
    "        \n",
    "        # if the column contains only numerical values, convert the data type to float\n",
    "        df[column] = df[column].astype(float)\n",
    "    \n",
    "# save the corrected dataset to a new file\n",
    "df.to_csv(\"corrected_data.csv\", index=False)''')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(14) 4.5.3 Strings in human-friendly formats (str-human):   \n",
    "Numerical information being represented in a human-friendly format is a smell for potential problems during the data analysis stage.   \n",
    "Machine learning models generally perform better when trained with standardised and uniform data.   \n",
    "Converting numerical information from a human-friendly format to a useful numerical representation can be challenging and may require domain knowledge or further investigation.   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no human-friendly formats in the dataset.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Define regex pattern for human-friendly formats\n",
    "pattern = r'^\\d{1,3}(,\\d{3})*(\\.\\d+)?$'\n",
    "hum = False\n",
    "# Loop through columns and check for human-friendly formats\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        if df[col].str.match(pattern).all():\n",
    "            # detected human-friendly format\n",
    "            print(f\"Column '{col}' contains human-friendly format\")\n",
    "            hum = True\n",
    "            # # Convert human-friendly format to float\n",
    "            # df[col] = df[col].str.replace(',', '').astype(float)\n",
    "if hum:\n",
    "    print('''\n",
    "    For converting the human-friendly format to float:\n",
    "    Code snippet:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            if df[col].str.match(pattern).all():\n",
    "                # detected human-friendly format\n",
    "                # Convert human-friendly format to float\n",
    "                df[col] = df[col].str.replace(',', '').astype(float)''')\n",
    "else:\n",
    "    print(\"There are no human-friendly formats in the dataset.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1e76f36fd497ba09966a644cdb5ca2914f26d4c9a4ffe25cd98fef631710b92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
